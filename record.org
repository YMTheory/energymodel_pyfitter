* Python Advanced in Fitting

** 测试代码运行时间（Line_profiler）
 - kernprof -l script_to_profile.py
 - @profile
   def slow_function(a, b, c):
       ...
 - python -m line_profiler script_to_profile.py.lprof

 ;;  [[[[file:./time_profiler_0821.png]]]]
 - The _calc function for each source takes around 1.8s each time, and the figure displays the time profiles.
 - 可以看见主要的时间开销还是在vectorized的三个array计算上面。

   
** Numba acceleration:
Numba: nopython mode, just-in-time compilation. （普通python程序编译时候需要每一次将程序语言解释为机器语言，因此相对缓慢）;

- Numba编译需要确定的数据类型，否则将退化回普通的解释型运行
- 尝试对大量numpy计算的部分进行优化。


*** Try to use numba.vectorize / nb.guvectorize method...
- 尝试将计算闪烁光子个数，切伦科夫光子个数以及光子数涨落的函数进行vectorize；
- 闪烁光子的计算遇到问题，目前的idea是传入kB对应的nonlinearity曲线，需要用numba.guvectorize装饰器
     - 目前还会出现报错：
    NumbaWarning: Compilation is falling back to object mode WITHOUT looplifting enabled
because Function "_get_Nsct" failed type inference due to: No implementation of function Function(<class 'int'>) found for signature:
  - 如果仅仅不对get_Nsct做numba.vectorize操作，单次_calc的运算大约需要800ms+，profile的结果如下：
  ;;- [[file:./time_profile_0822.png]]
  - （运行了profiler之后整体运行时间会变长，约2s）可以看出，此时程序占用时间最长的部分是get_Nsct()。
  - 使用numba.guvectorize的函数后甚至更慢了，其并没能nopython compilation；
  - 将Eid也作为一个参数输入后，不再有上述错误，对scalar可以运行了，但是对于array仍不行，有如下报错：
    ufunc '_get_Nsct' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''。
  - 原因可能是对input参数的维度定义不对，修改了guvectorize里参数的类型和维数，并在内部用了循环。NOW IT WORKS!!!
   且运行时间变成了40ms+，提高了20倍左右； 

  - 目前的测试结果，一次_calc的运行大约不到40-50ms，跑一个完整的iminuit-based UnbinnedNLL（9个gamma source的联合拟合）不到十分钟。

*** 尝试CUDA对fitter进行加速：
- 在服务器上使用CUDA资源；
  #+BEGIN_SRC python
    nb.vectorize(signatures, target="cuda")
  #+END_SRC
np.exp, np.sqrt methods are unsupported in CUDA, need to be replaced by math.exp, math.sqrt...
如果所有函数都不用cuda操作，全部用cpu上的编译模式运行，得到的结果是大约1.3s一次；（远比cpu上的运行要慢，很可能是由于内存读写引起的耗时）
如果不对Nsct做cuda操作，一个事例运行大约需要200+ms；

- 另一个option是用cuda.jit(device=True)来尝试进行运行，而不用vectorize
在集群上测试了这个方法，需要设置thread，grid等信息，稍微改动看了下，没有明显区别，且这样比get_Nsct直接使用guvectorize的方法要慢，大约要300ms+。

- Memory Management: 尝试将elec/posi以及ID提前先传到device，利用（cuda.to_device）方法。然后调用kernel function，直接用device array。然而提升很有限，大约降到280ms左右。

- 用line_profiler比较了一下，使用cuda和不使用cuda的程序，似乎不使用cuda的会快一些，不知道是不是由于data transfer引起的，需要想办法对此进行一个测试。

- Updates: 之前对cuda.jit的调用应该是没有正确实现并行，修改了里面的实现，需要先返回grid，然后对指定位置的数组元素进行计算。目前速度降到了70ms+一次运算。

- Updates: 修改了guvectorize，使得在cuda模式下可用，一个关键是需要确保所有输入的array的类型与signatures相一致，目前的做法是在input之前对array都做一个astype的强制类型转换。
  - 目前的结果是，在JUNO GPU集群上，使用cuda.jit装饰器或者用guvectorize(target="cuda")的速度差不多，都是大约80ms一次计算。
  - nvprof python xxx 可以测试各个API的耗时。
    测试时候发现Driver API: cuAddLinkData耗时似乎很多。
  - 已经把quenching非线性曲线，以及Nsct的初始化都放到了device，时间没有进一步缩短，现在一个计算大约60ms左右。仍长于cpu parallel。



*** 加入能谱拟合的部分：
- 例如B12能谱，之前的做法是串行的，先用fine binning去加上能量响应，在smear到coarse binning，在python大约600ms一次ApplyResponse.
- combined NLL 后，似乎在conda juno环境上可以跑通，但在pyvenv my_env环境里会有奇怪报错。。
- 经过比较两个版本，发现my_env下，numpy=1.22的interp函数返回值为None从而引起报错。然而升级后发现，numba=0.56.1只支持<=1.22的numpy。因此将numba降级为0.53后可以使用。
*** Numba Manual:
- In CUDA, the code you write will be executed by multiple threads at once (often hundreds or thousands). Your solution will be modeled by defining a thread hierarchy of grid, blocks and threads.
- Kernel declaration:
- 不显示返回结果，只是讲结果写入到传入的列表里。需要在内部定义线程等级，thread blocks的个数以及每个block中thread的个数；
  #+BEGIN_SRC python
    @cuda.jit
    def increment_by_one(an_array):
    # Increment all elements in an array...
  #+END_SRC   

  
And a kernel is launched by,
#+BEGIN_SRC python
threadsperblock = 32
blockspergrid = (an_array.size + (threadsperblock - 1)) // threadsperblock
increment_by_one[blockspergrid, threadsperblock](an_array)
#+END_SRC

- Running the kernel, by passing it the input array (and any separate output arrays if necessary). By default, running a kernel is synchronous: the function returns when the kernel has finished executing and the data is synchronized back.
- Numba can transfer numpy array to the device conservatively when a kernel is finished;


